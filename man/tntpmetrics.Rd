% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tntpmetric_outputs.R
\name{tntpmetrics}
\alias{tntpmetrics}
\alias{metric_mean}
\alias{metric_growth}
\title{Compute single common metric mean, difference between groups, and/or change over time.}
\usage{
metric_mean(
  data,
  metric,
  equity_group = NULL,
  by_class = F,
  scaleusewarning = T
)

metric_growth(
  data1,
  data2,
  metric,
  equity_group = NULL,
  by_class = F,
  scaleusewarning = T
)
}
\arguments{
\item{data}{Data from a single timepoint. Used in \code{metric_mean}.}

\item{metric}{Quoted name of the common metric. Options are "engagement", "belonging",
"relevance", "assignments", "tntpcore", or "ipg".}

\item{equity_group}{Optional quoted name of the categorical column/variable in data that contains
the equity group designation. For example, if data has an indicator variable called
\code{class_frl} that is either "Under 50% students with FRL" or "50% or more students with
FRL", then analyst could set \code{equity_group = "class_frl"} to get differences in metric
between these two groups. Default is no equity comparison.}

\item{by_class}{A logical (T/F) option indicating if multiple rows of data come from the same
class. When \code{by_class = T}, analysis will automatically account for different sample sizes
between classes and adjust the standard errors to account for the lack of independence between
data deriving from the same class. If set to \code{FALSE}, data must have a variable titled
\code{class_id}. Default if \code{FALSE}.}

\item{scaleusewarning}{A logical (T/F) indicating whether function should generate a warning when
not all values of a scale are used. For example, student survey data that only contains values
of 1s and 2s could mean that data is on a 1-4 scale, when it should be on a 0-3 scale. When
\code{scaleusewarning = T}, the function will warn you of this. This warning does not mean your
data is wrong. For example, the Academic Ownership domain from TNTP CORE has 5 potential
values: 1, 2, 3, 4, or 5. It's not uncommon to have data where teachers were never rated above
a 4 on this domain. In this case, the printed warning can be ignored. Default if \code{TRUE}.
If you are confident your data is on the right scale, you can suppress the warning by setting
to \code{TRUE}.}

\item{data1}{Data from the initial timepoint. Used in \code{metric_growth}.}

\item{data2}{Data from the final timepoint. Used in \code{metric_growth}.}
}
\value{
A list of results including the overall mean or mean by equity group (for
  \code{metric_mean}), the mean change over time or mean change for each group (for
  \code{metric_growth}). Means are accompanied by standard errors and 95% confidence
  intervals. Also included are list elements for number of data points used in analysis.
}
\description{
\code{metric_mean} computes the mean common metric score at a single point in time.
  \code{metric_growth} computes the mean change in the common metric score between two points
  in time. Both functions can disaggregate  results based on a group characteristic used for
  equity comparisons. They can also account for metrics where multiple data points come from the
  same classroom, like those based on student surveys or assignments.
}
\section{Data and Variable Format}{

  \code{metric_mean} and \code{metric_growth} should be used with the raw metric data.
  Each row of data should represent a single rated outcome. For example, each row of data will be
  a single completed survey, a single rated assignment, a single classroom observation, etc.
  The data should not have the metric already calculated but instead have the components needed
  to make this calculation. For example, data on student engagement should not have a column or
  variable titled engagement, but should have variables corresponding the four survey questions
  used to calculate engagement. Leave all items in their raw form - the functions automatically
  account for items that need to be reverse coded. The only requirement is that the data contains
  the needed variables and that the variables are numeric (i.e., data values should be 0s and 1s,
  not 'No' and 'Yes'. This ensures that the common metrics are calculated correctly and
  consistently across projects. Each metric has its own set of needed variables that must be
  spelled exactly as shown below. They are:
  \describe{
    \item{engagement:}{eng_like, eng_losttrack, eng_interest, eng_moreabout}
    \item{belonging:}{tch_problem, bel_ideas, bel_fitin, tch_interestedideas}
    \item{relevance:}{rel_asmuch, rel_future, rel_outside, rel_rightnow}
    \item{expectations:}{exp_mastergl, exp_toochallenging, exp_oneyear, exp_different,
      exp_overburden, exp_began}
    \item{tntpcore:}{ec, ao, dl, cl}
    \item{ipg:}{ca1_a, ca1_b, ca1_c, ca2_overall, ca3_overall, col, rfs_overall}
   }
 See the vignette for more details.
}

\examples{
# Compute the mean engagement score for an entire project at a single time point. Setting
# by_class = T because multiple surveys come from the same class.
metric_mean(practice_data, metric = "engagement", by_class = T)

# Do the same, but now compare results by a class's FRL population
metric_mean(practice_data, metric = "engagement", equity_group = "frl_cat", by_class = T)

# Look at change in engagement over time, then look at how differences in engagement between a
# class's FRL population change over time
metric_growth(
  practice_data_initial,
  practice_data_final,
  metric = "engagement",
  by_class = T
 )
 metric_growth(
  practice_data_initial,
  practice_data_final,
  metric = "engagement",
  equity_group = "class_frl_cat",
  by_class = T
 )

}
